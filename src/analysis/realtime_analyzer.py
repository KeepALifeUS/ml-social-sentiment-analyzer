"""
–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏

–í—ã—Å–æ–∫–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ—Ç–æ–∫–æ–≤ —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
–≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏ with enterprise patterns.
"""

import asyncio
import time
from typing import Dict, List, Optional, Any, AsyncGenerator
from datetime import datetime
from dataclasses import dataclass
import numpy as np
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import structlog
from circuitbreaker import CircuitBreaker
import aioredis

from ..utils.config import Config
from ..monitoring.metrics_collector import MetricsCollector
from ..nlp.preprocessor import TextPreprocessor
from ..ml.ensemble_model import EnsembleModel

logger = structlog.get_logger(__name__)

@dataclass
class SentimentResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è."""
    text: str
    sentiment: str  # positive, negative, neutral
    confidence: float
    scores: Dict[str, float]  # –î–µ—Ç–∞–ª—å–Ω—ã–µ –æ—Ü–µ–Ω–∫–∏
    crypto_symbols: List[str]
    processing_time_ms: float
    model_version: str
    timestamp: datetime

class RealtimeSentimentAnalyzer:
    """
    Enterprise –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
    
    Features:
    - –í—ã—Å–æ–∫–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å (>1000 —Å–æ–æ–±—â–µ–Ω–∏–π/—Å–µ–∫)
    - Ensemble –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏
    - Crypto-specific –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
    - Circuit breaker –∏ fallback
    - Redis –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ
    - Batch processing –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
    """
    
    def __init__(self, config: Config):
        self.config = config
        self.metrics = MetricsCollector("realtime_sentiment_analyzer")
        self.logger = logger.bind(component="realtime_sentiment_analyzer")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        self.preprocessor = TextPreprocessor()
        self.ensemble_model: Optional[EnsembleModel] = None
        self._redis: Optional[aioredis.Redis] = None
        
        # Circuit breaker –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç –ø–µ—Ä–µ–≥—Ä—É–∑–∫–∏
        self._circuit_breaker = CircuitBreaker(
            failure_threshold=5,
            recovery_timeout=30,
            expected_exception=Exception
        )
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self.batch_size = config.realtime_batch_size or 32
        self.max_queue_size = config.realtime_max_queue_size or 1000
        self.processing_timeout = config.realtime_timeout or 1.0  # —Å–µ–∫—É–Ω–¥—ã
        
        # –û—á–µ—Ä–µ–¥–∏ –¥–ª—è batch processing
        self._input_queue = asyncio.Queue(maxsize=self.max_queue_size)
        self._result_cache = {}
        self._cache_ttl = 300  # 5 –º–∏–Ω—É—Ç –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        self._processed_count = 0
        self._error_count = 0
        self._start_time = time.time()
        
        # Crypto-specific –≤–µ—Å–∞
        self.crypto_sentiment_weights = {
            "moon": 0.8,      # –û—á–µ–Ω—å –ø–æ–∑–∏—Ç–∏–≤–Ω–æ
            "lambo": 0.7,     # –ü–æ–∑–∏—Ç–∏–≤–Ω–æ 
            "hodl": 0.6,      # –£–º–µ—Ä–µ–Ω–Ω–æ –ø–æ–∑–∏—Ç–∏–≤–Ω–æ
            "dump": -0.8,     # –û—á–µ–Ω—å –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ
            "crash": -0.9,    # –ö—Ä–∞–π–Ω–µ –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ
            "bear": -0.6,     # –ù–µ–≥–∞—Ç–∏–≤–Ω–æ
            "bull": 0.7,      # –ü–æ–∑–∏—Ç–∏–≤–Ω–æ
            "diamond hands": 0.8,  # –û—á–µ–Ω—å –ø–æ–∑–∏—Ç–∏–≤–Ω–æ
            "paper hands": -0.5,   # –ù–µ–≥–∞—Ç–∏–≤–Ω–æ
            "whale": 0.3,     # –°–ª–∞–±–æ –ø–æ–∑–∏—Ç–∏–≤–Ω–æ (–º–æ–∂–µ—Ç –±—ã—Ç—å –∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ)
            "fomo": -0.2,     # –°–ª–∞–±–æ –Ω–µ–≥–∞—Ç–∏–≤–Ω–æ
            "fud": -0.7,      # –ù–µ–≥–∞—Ç–∏–≤–Ω–æ
        }
    
    async def initialize(self) -> None:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞."""
        try:
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Redis
            self._redis = aioredis.from_url(
                self.config.redis_url,
                encoding="utf-8",
                decode_responses=True
            )
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ensemble –º–æ–¥–µ–ª–∏
            self.ensemble_model = EnsembleModel(self.config)
            await self.ensemble_model.initialize()
            
            # –ó–∞–ø—É—Å–∫ batch processor
            asyncio.create_task(self._batch_processor())
            
            self.logger.info("Real-time sentiment analyzer initialized",
                           batch_size=self.batch_size,
                           max_queue_size=self.max_queue_size)
            
        except Exception as e:
            self.logger.error("Failed to initialize analyzer", error=str(e))
            raise
    
    @CircuitBreaker(failure_threshold=5, recovery_timeout=30)
    async def analyze_sentiment(
        self,
        text: str,
        platform: str = "unknown",
        priority: int = 1  # 1=high, 2=medium, 3=low
    ) -> SentimentResult:
        """
        –ê–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –æ–¥–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
        
        Args:
            text: –¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            platform: –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
            priority: –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏
        """
        
        start_time = time.time()
        
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞
            cache_key = f"sentiment:{hash(text)}:{platform}"
            cached_result = await self._get_from_cache(cache_key)
            if cached_result:
                self.metrics.increment("cache_hits")
                return cached_result
            
            # –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ —Ç–µ–∫—Å—Ç–∞
            preprocessed_text = self.preprocessor.preprocess(text)
            
            # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ crypto —Å–∏–º–≤–æ–ª–æ–≤
            crypto_symbols = self.preprocessor.extract_crypto_symbols(text)
            
            # –ê–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ ensemble –º–æ–¥–µ–ª—å
            sentiment_scores = await self.ensemble_model.predict(preprocessed_text)
            
            # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ crypto-specific –≤–µ—Å–æ–≤
            adjusted_scores = self._apply_crypto_weights(
                sentiment_scores, preprocessed_text, crypto_symbols
            )
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è
            sentiment = self._determine_sentiment(adjusted_scores)
            confidence = max(adjusted_scores.values())
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            processing_time = (time.time() - start_time) * 1000
            
            result = SentimentResult(
                text=text,
                sentiment=sentiment,
                confidence=confidence,
                scores=adjusted_scores,
                crypto_symbols=crypto_symbols,
                processing_time_ms=processing_time,
                model_version=self.ensemble_model.version,
                timestamp=datetime.now()
            )
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∫—ç—à
            await self._save_to_cache(cache_key, result)
            
            # –ú–µ—Ç—Ä–∏–∫–∏
            self.metrics.increment("messages_processed")
            self.metrics.histogram("processing_time_ms", processing_time)
            self._processed_count += 1
            
            return result
            
        except Exception as e:
            self.logger.error("Sentiment analysis failed", text=text[:100], error=str(e))
            self.metrics.increment("analysis_errors")
            self._error_count += 1
            
            # Fallback —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            return SentimentResult(
                text=text,
                sentiment="neutral",
                confidence=0.5,
                scores={"positive": 0.33, "negative": 0.33, "neutral": 0.34},
                crypto_symbols=[],
                processing_time_ms=(time.time() - start_time) * 1000,
                model_version="fallback",
                timestamp=datetime.now()
            )
    
    async def analyze_batch(
        self,
        texts: List[str],
        platform: str = "unknown"
    ) -> List[SentimentResult]:
        """Batch –∞–Ω–∞–ª–∏–∑ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""
        
        if not texts:
            return []
        
        start_time = time.time()
        results = []
        
        try:
            # –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ –≤—Å–µ–≥–æ batch
            preprocessed_texts = [
                self.preprocessor.preprocess(text) for text in texts
            ]
            
            # Batch –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —á–µ—Ä–µ–∑ ensemble
            batch_scores = await self.ensemble_model.predict_batch(preprocessed_texts)
            
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            for i, (text, scores) in enumerate(zip(texts, batch_scores)):
                crypto_symbols = self.preprocessor.extract_crypto_symbols(text)
                
                # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ crypto –≤–µ—Å–æ–≤
                adjusted_scores = self._apply_crypto_weights(
                    scores, preprocessed_texts[i], crypto_symbols
                )
                
                sentiment = self._determine_sentiment(adjusted_scores)
                confidence = max(adjusted_scores.values())
                
                result = SentimentResult(
                    text=text,
                    sentiment=sentiment,
                    confidence=confidence,
                    scores=adjusted_scores,
                    crypto_symbols=crypto_symbols,
                    processing_time_ms=0,  # –ë—É–¥–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–∑–∂–µ
                    model_version=self.ensemble_model.version,
                    timestamp=datetime.now()
                )
                
                results.append(result)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏
            total_time = (time.time() - start_time) * 1000
            avg_time = total_time / len(results)
            
            for result in results:
                result.processing_time_ms = avg_time
            
            self.metrics.increment("batch_processed", len(results))
            self.metrics.histogram("batch_processing_time_ms", total_time)
            
            return results
            
        except Exception as e:
            self.logger.error("Batch analysis failed", batch_size=len(texts), error=str(e))
            self.metrics.increment("batch_errors")
            
            # Fallback –¥–ª—è –≤—Å–µ–≥–æ batch
            return [
                SentimentResult(
                    text=text,
                    sentiment="neutral",
                    confidence=0.5,
                    scores={"positive": 0.33, "negative": 0.33, "neutral": 0.34},
                    crypto_symbols=[],
                    processing_time_ms=0,
                    model_version="fallback",
                    timestamp=datetime.now()
                )
                for text in texts
            ]
    
    async def stream_analyze(
        self,
        message_stream: AsyncGenerator[Dict[str, Any], None]
    ) -> AsyncGenerator[SentimentResult, None]:
        """–ü–æ—Ç–æ–∫–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""
        
        batch_buffer = []
        last_flush_time = time.time()
        
        async for message in message_stream:
            try:
                text = message.get("text", "")
                platform = message.get("platform", "unknown")
                
                if not text:
                    continue
                
                # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –≤ batch buffer
                batch_buffer.append((text, platform, message))
                
                # –£—Å–ª–æ–≤–∏—è –¥–ª—è flush batch
                should_flush = (
                    len(batch_buffer) >= self.batch_size or
                    (time.time() - last_flush_time) > self.processing_timeout
                )
                
                if should_flush:
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ batch
                    texts = [item[0] for item in batch_buffer]
                    platforms = [item[1] for item in batch_buffer]
                    messages = [item[2] for item in batch_buffer]
                    
                    # –ê–Ω–∞–ª–∏–∑ batch
                    results = await self.analyze_batch(texts, platforms[0])
                    
                    # Yield —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
                    for result, original_msg in zip(results, messages):
                        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è
                        enhanced_result = result
                        enhanced_result.platform = original_msg.get("platform")
                        enhanced_result.message_id = original_msg.get("id")
                        enhanced_result.author = original_msg.get("author")
                        
                        yield enhanced_result
                    
                    # –û—á–∏—Å—Ç–∫–∞ buffer
                    batch_buffer.clear()
                    last_flush_time = time.time()
                
            except Exception as e:
                self.logger.error("Stream processing error", error=str(e))
                continue
        
        # Flush –æ—Å—Ç–∞–≤—à–∏—Ö—Å—è —Å–æ–æ–±—â–µ–Ω–∏–π
        if batch_buffer:
            texts = [item[0] for item in batch_buffer]
            results = await self.analyze_batch(texts)
            
            for result in results:
                yield result
    
    def _apply_crypto_weights(
        self,
        scores: Dict[str, float],
        text: str,
        crypto_symbols: List[str]
    ) -> Dict[str, float]:
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ crypto-specific –≤–µ—Å–æ–≤ –∫ –æ—Ü–µ–Ω–∫–∞–º."""
        
        text_lower = text.lower()
        adjustment = 0.0
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –¥–ª—è crypto —Ç–µ—Ä–º–∏–Ω–æ–≤
        for term, weight in self.crypto_sentiment_weights.items():
            if term in text_lower:
                adjustment += weight * 0.1  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –≤–ª–∏—è–Ω–∏—è
        
        # –ë–æ–Ω—É—Å –∑–∞ —É–ø–æ–º–∏–Ω–∞–Ω–∏–µ crypto —Å–∏–º–≤–æ–ª–æ–≤
        if crypto_symbols:
            symbol_bonus = min(len(crypto_symbols) * 0.05, 0.2)  # –ú–∞–∫—Å 20%
            adjustment += symbol_bonus if scores.get("positive", 0) > scores.get("negative", 0) else -symbol_bonus
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ adjustment –∫ –æ—Ü–µ–Ω–∫–∞–º
        adjusted_scores = scores.copy()
        
        if adjustment > 0:
            adjusted_scores["positive"] = min(1.0, adjusted_scores.get("positive", 0) + abs(adjustment))
            adjusted_scores["negative"] = max(0.0, adjusted_scores.get("negative", 0) - abs(adjustment) * 0.5)
        elif adjustment < 0:
            adjusted_scores["negative"] = min(1.0, adjusted_scores.get("negative", 0) + abs(adjustment))
            adjusted_scores["positive"] = max(0.0, adjusted_scores.get("positive", 0) - abs(adjustment) * 0.5)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        total = sum(adjusted_scores.values())
        if total > 0:
            adjusted_scores = {k: v / total for k, v in adjusted_scores.items()}
        
        return adjusted_scores
    
    def _determine_sentiment(self, scores: Dict[str, float]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏—Ç–æ–≥–æ–≤–æ–≥–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è."""
        
        # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        min_confidence = 0.4
        
        max_score = max(scores.values())
        if max_score < min_confidence:
            return "neutral"
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –æ—Ü–µ–Ω–∫–µ
        return max(scores.items(), key=lambda x: x[1])[0]
    
    async def _get_from_cache(self, key: str) -> Optional[SentimentResult]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –∏–∑ –∫—ç—à–∞."""
        
        if not self._redis:
            return None
        
        try:
            cached_data = await self._redis.get(key)
            if cached_data:
                # –î–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞)
                import json
                data = json.loads(cached_data)
                return SentimentResult(**data)
        except Exception as e:
            self.logger.debug("Cache read failed", key=key, error=str(e))
        
        return None
    
    async def _save_to_cache(self, key: str, result: SentimentResult) -> None:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –≤ –∫—ç—à."""
        
        if not self._redis:
            return
        
        try:
            # –°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è (—É–ø—Ä–æ—â–µ–Ω–Ω–∞—è)
            import json
            data = {
                "text": result.text,
                "sentiment": result.sentiment,
                "confidence": result.confidence,
                "scores": result.scores,
                "crypto_symbols": result.crypto_symbols,
                "processing_time_ms": result.processing_time_ms,
                "model_version": result.model_version,
                "timestamp": result.timestamp.isoformat()
            }
            
            await self._redis.setex(key, self._cache_ttl, json.dumps(data))
            
        except Exception as e:
            self.logger.debug("Cache write failed", key=key, error=str(e))
    
    async def _batch_processor(self) -> None:
        """Background –∑–∞–¥–∞—á–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ queue."""
        
        while True:
            try:
                # –°–±–æ—Ä batch –∏–∑ –æ—á–µ—Ä–µ–¥–∏
                batch = []
                deadline = time.time() + self.processing_timeout
                
                while len(batch) < self.batch_size and time.time() < deadline:
                    try:
                        item = await asyncio.wait_for(
                            self._input_queue.get(),
                            timeout=deadline - time.time()
                        )
                        batch.append(item)
                    except asyncio.TimeoutError:
                        break
                
                if batch:
                    # –û–±—Ä–∞–±–æ—Ç–∫–∞ batch
                    texts = [item["text"] for item in batch]
                    results = await self.analyze_batch(texts)
                    
                    # –í–æ–∑–≤—Ä–∞—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                    for item, result in zip(batch, results):
                        if "callback" in item:
                            asyncio.create_task(item["callback"](result))
                
                # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞
                await asyncio.sleep(0.01)
                
            except Exception as e:
                self.logger.error("Batch processor error", error=str(e))
                await asyncio.sleep(1)
    
    async def get_performance_stats(self) -> Dict[str, Any]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏."""
        
        uptime = time.time() - self._start_time
        throughput = self._processed_count / uptime if uptime > 0 else 0
        error_rate = self._error_count / max(self._processed_count, 1)
        
        return {
            "uptime_seconds": uptime,
            "messages_processed": self._processed_count,
            "error_count": self._error_count,
            "error_rate": error_rate,
            "throughput_msg_per_sec": throughput,
            "queue_size": self._input_queue.qsize(),
            "circuit_breaker_state": str(self._circuit_breaker.current_state),
            "metrics": self.metrics.get_metrics()
        }
    
    async def health_check(self) -> Dict[str, Any]:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞."""
        
        try:
            # –¢–µ—Å—Ç–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
            test_result = await self.analyze_sentiment(
                "Bitcoin is going to the moon! üöÄ",
                platform="test"
            )
            
            perf_stats = await self.get_performance_stats()
            
            return {
                "status": "healthy" if test_result.sentiment else "unhealthy",
                "model_loaded": self.ensemble_model is not None,
                "redis_connected": self._redis is not None,
                "test_analysis": {
                    "sentiment": test_result.sentiment,
                    "confidence": test_result.confidence,
                    "processing_time_ms": test_result.processing_time_ms
                },
                "performance": perf_stats
            }
            
        except Exception as e:
            return {
                "status": "unhealthy",
                "error": str(e)
            }
    
    async def shutdown(self) -> None:
        """Graceful shutdown –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞."""
        
        self.logger.info("Shutting down real-time sentiment analyzer")
        
        # –ó–∞–∫—Ä—ã—Ç–∏–µ Redis —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
        if self._redis:
            await self._redis.close()
        
        # –û—Å—Ç–∞–Ω–æ–≤–∫–∞ ensemble –º–æ–¥–µ–ª–∏
        if self.ensemble_model:
            await self.ensemble_model.shutdown()